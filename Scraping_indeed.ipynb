{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Scrapper\n",
    "\n",
    "\n",
    "This notebook contains a function named scrape_jobs_indeed(), serving as a pipeline to automate the process of opening the browser, navigating to indeed.com, selecting the desired city and job title. Subsequently, it proceeds to scrape the initial page of job listings. Due to limitations imposed by the website's security measures, we are restricted to scraping only the first page of job offers. Attempting to access subsequent pages triggers the website's bot detection system, recognizing the user as non-human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, StaleElementReferenceException\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pandas\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
    "\n",
    "# Go get geckodriver from : https://github.com/mozilla/geckodriver/releases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ffx_preferences(dfolder, download=False):\n",
    "    '''\n",
    "    Sets the preferences of the firefox browser: download path.\n",
    "    '''\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    # set download folder:\n",
    "    profile.set_preference(\"browser.download.dir\", dfolder)\n",
    "    profile.set_preference(\"browser.download.folderList\", 2)\n",
    "    profile.set_preference(\"browser.download.manager.showWhenStarting\", False)\n",
    "    profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\",\n",
    "                           \"application/msword,application/rtf, application/csv,text/csv,image/png ,image/jpeg, application/pdf, text/html,text/plain,application/octet-stream\")\n",
    "\n",
    "    # this allows to download pdfs automatically\n",
    "    if download:\n",
    "        profile.set_preference(\"browser.helperApps.neverAsk.saveToDisk\", \"application/pdf,application/x-pdf\")\n",
    "        profile.set_preference(\"pdfjs.disabled\", True)\n",
    "\n",
    "    options = Options()\n",
    "    options.profile = profile\n",
    "    return options\n",
    "\n",
    "\n",
    "def start_up(link, geko_path, profile_path=None, browser=None):\n",
    "        \"\"\"\n",
    "        Function to set up the browser and open the selected link.\n",
    "\n",
    "        Args:\n",
    "            link (str): The URL to open.\n",
    "            geko_path (str): Path to the Gecko driver executable.\n",
    "            profile_path (str): Path to the Firefox profile to be used if there is any.\n",
    "            browser: Optional existing webdriver instance.\n",
    "\n",
    "        Returns:\n",
    "            browser: The initialized webdriver instance.\n",
    "        \"\"\"\n",
    "        if not browser:\n",
    "            if profile_path:\n",
    "                firefox_options = webdriver.FirefoxOptions()\n",
    "                firefox_options.add_argument(f'--profile={profile_path}')\n",
    "                service = Service(geko_path)\n",
    "                browser = webdriver.Firefox(service=service, options=firefox_options)\n",
    "            else:\n",
    "                profile = webdriver.FirefoxProfile()\n",
    "                options = Options()\n",
    "                options.profile = profile\n",
    "                service = Service(geko_path)\n",
    "                browser = webdriver.Firefox(service=service, options=options)\n",
    "        browser.get(link)\n",
    "        time.sleep(2)\n",
    "        return browser\n",
    "        \n",
    "def check_and_click(browser, xpath, type):\n",
    "    '''\n",
    "    Function that checks whether the object is clickable and, if so, clicks on\n",
    "    it. If not, waits one second and tries again.\n",
    "    '''\n",
    "    start_time = time.time()  # Record the start time\n",
    "    while True:\n",
    "        try:\n",
    "            element = browser.find_element(By.XPATH, xpath)\n",
    "            element.click()\n",
    "            return \"Clicked!\"  # Element found and clicked successfully\n",
    "        except NoSuchElementException:\n",
    "            pass  # Continue if element not found\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return False  # Other unexpected errors\n",
    "\n",
    "        time.sleep(1)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time >= 3:\n",
    "            print(\"** The element was not found in the page. **\")\n",
    "            return None  # Element not found after 5 seconds\n",
    "        \n",
    "def check_obscures(browser, xpath, type):\n",
    "    '''\n",
    "    Function that checks whether the object is being \"obscured\" by any element so\n",
    "    that it is not clickable. Important: if True, the object is going to be clicked!\n",
    "    '''\n",
    "    try:\n",
    "        if type == \"xpath\":\n",
    "            browser.find_element('xpath', xpath).click()\n",
    "        elif type == \"id\":\n",
    "            browser.find_element('id', xpath).click()\n",
    "        elif type == \"css\":\n",
    "            browser.find_element('css selector', xpath).click()\n",
    "        elif type == \"class\":\n",
    "            browser.find_element('class name', xpath).click()\n",
    "        elif type == \"link\":\n",
    "            browser.find_element('link text', xpath).click()\n",
    "    except (ElementClickInterceptedException, StaleElementReferenceException) as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    except NoSuchElementException:\n",
    "        # Do nothing if NoSuchElementException occurs (suppress the error)\n",
    "        pass\n",
    "    return True\n",
    "\n",
    "def element_exists(browser, path):\n",
    "    try:\n",
    "        browser.find_element('xpath', path)\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the geckodriver executable:\n",
    "geko_path='C:/Users/School/Downloads/geckodriver-v0.34.0-win64/geckodriver.exe'\n",
    "link='https://www.indeed.com/jobs?q=python&l=LA'\n",
    "\n",
    "# If fifefox profile is needed, set the path to the profile:\n",
    "profile_path = ''\n",
    "\n",
    "browser=start_up(link=link,geko_path=geko_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words = [‘university’, 'Los Angeles', 'New York','Chicago','San Fransisco' ,'Austin','Seattle','Boston','Washington','Houston','Atlanta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n",
      "Location:  Los Angeles\n",
      "Location:  New York\n",
      "Location:  Chicago\n",
      "Location:  San Fransisco\n"
     ]
    }
   ],
   "source": [
    "# loop to scrape the data and populate the DataFrame\n",
    "locations = ['Los Angeles', 'New York','Chicago','San Fransisco'] # ,'Austin','Seattle','Boston','Washington','Houston','Atlanta'] # Miami, \n",
    "jobs = ['Data Science','Mechanical Engineer','Sales','Java Developer', 'Business Analyst','Operations Manager', 'Python Developer', 'DevOps Engineer','Network Security Engineer', 'Database','Blockchain','ETL Developer']\n",
    "\n",
    "def scrape_jobs_indeed(job_list, location_list,geko_path,link):\n",
    "    data = pd.DataFrame(columns=['Job title', 'Company', 'Description', 'Job_Title_Searched', 'Location_Searched'])\n",
    "    for j in jobs:\n",
    "        for i in locations:\n",
    "            # Start browser\n",
    "            browser=start_up(link=link,geko_path=geko_path)\n",
    "            # Click on the search bar\n",
    "            browser.find_element(by='xpath',value='//input[@id=\"text-input-what\"]').click()\n",
    "            # Input job\n",
    "            search1 = browser.find_element(by='xpath',value='//input[@id=\"text-input-what\"]')\n",
    "            search1.clear()\n",
    "            search1.send_keys(j)\n",
    "\n",
    "            # Click on the location search bar\n",
    "            browser.find_element(by='xpath',value='//input[@id=\"text-input-where\"]').click()\n",
    "            # Input place\n",
    "            search1 = browser.find_element(by='xpath',value='//input[@id=\"text-input-where\"]')\n",
    "            search1.clear()\n",
    "            search1.send_keys(i)\n",
    "\n",
    "            # Click on the search bar\n",
    "            browser.find_element(by='xpath',value='//button[@class=\"yosegi-InlineWhatWhere-primaryButton\"]').click()\n",
    "            time.sleep(2)\n",
    "            \n",
    "            print(\"Location: \", i)\n",
    "            # Dividing the page in the Container Objects, one for every hotel and extracting the wanted data from each\n",
    "            containers = browser.find_elements(By.XPATH, '//li[@class=\"css-5lfssm eu4oa1w0\"]')\n",
    "            for job in containers:\n",
    "                try: \n",
    "                    job.click()\n",
    "                    random_sleep = np.random.randint(1, 2)\n",
    "                    time.sleep(1)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    job_title = job.find_element('xpath', '/html/body/main/div/div[2]/div/div[5]/div/div[2]/div/div/div[2]/div[2]/div[1]/div/div[1]/div[1]/h2/span').text\n",
    "                    if '\\n' in job_title:\n",
    "                        job_title = job_title.split('\\n')[0]\n",
    "                except:\n",
    "                    job_title = np.nan\n",
    "                try:\n",
    "                    job_company = job.find_element('xpath', '/html/body/main/div/div[2]/div/div[5]/div/div[2]/div/div/div[2]/div[2]/div[1]/div/div[1]/div[2]/div/div/div/div[1]/div[1]/span/a').text\n",
    "                except:\n",
    "                    job_company = np.nan\n",
    "                try: \n",
    "                    job_location = job.find_element('xpath', '//*[@id=\"jobLocationSectionWrapper\"]').text\n",
    "                    if '\\n' in job_location:\n",
    "                        job_location = job_location.split('\\n')[1]\n",
    "                except:\n",
    "                    job_location = np.nan\n",
    "                try:\n",
    "                    job_description = browser.find_element('xpath', '//*[@id=\"jobDescriptionText\"]').text\n",
    "                except:\n",
    "                    job_description = np.nan\n",
    "                new_row = {'Job title': job_title, 'Company': job_company, 'Description':job_description, 'Location':job_location, 'Job_Title_Searched':j, 'Location_Searched':i}\n",
    "                data = pd.concat([data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            time.sleep(1)\n",
    "            browser.quit()\n",
    "    return data\n",
    "\n",
    "data2 = scrape_jobs_indeed(jobs, locations, geko_path,link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the scraped data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "data2.to_csv('jobs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job_Title_Searched</th>\n",
       "      <th>Location_Searched</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>About the California Policy Lab\\nThe Californi...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research Data Scientist</td>\n",
       "      <td>CEDARS-SINAI</td>\n",
       "      <td>Job Description\\nThe Research Data Scientist p...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Expatiate Communications is a boutique managem...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Pasadena, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>Los Angeles County Department of Human Resources</td>\n",
       "      <td>EXAM NUMBER:\\nPH1763B\\n\\nTYPE OF RECRUITMENT:\\...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles County, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Predictive Data Analyst - CalAIM</td>\n",
       "      <td>Heluna Health</td>\n",
       "      <td>Salary: $42.59 - $57.40 Per Hour\\nSUMMARY\\nCom...</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Los Angeles, CA 90014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Job title  \\\n",
       "0                      Data Analyst   \n",
       "1           Research Data Scientist   \n",
       "2                    Data Scientist   \n",
       "3                    DATA SCIENTIST   \n",
       "4  Predictive Data Analyst - CalAIM   \n",
       "\n",
       "                                            Company  \\\n",
       "0                                              UCLA   \n",
       "1                                      CEDARS-SINAI   \n",
       "2                                               NaN   \n",
       "3  Los Angeles County Department of Human Resources   \n",
       "4                                     Heluna Health   \n",
       "\n",
       "                                         Description Job_Title_Searched  \\\n",
       "0  About the California Policy Lab\\nThe Californi...       Data Science   \n",
       "1  Job Description\\nThe Research Data Scientist p...       Data Science   \n",
       "2  Expatiate Communications is a boutique managem...       Data Science   \n",
       "3  EXAM NUMBER:\\nPH1763B\\n\\nTYPE OF RECRUITMENT:\\...       Data Science   \n",
       "4  Salary: $42.59 - $57.40 Per Hour\\nSUMMARY\\nCom...       Data Science   \n",
       "\n",
       "  Location_Searched                Location  \n",
       "0       Los Angeles         Los Angeles, CA  \n",
       "1       Los Angeles         Los Angeles, CA  \n",
       "2       Los Angeles            Pasadena, CA  \n",
       "3       Los Angeles  Los Angeles County, CA  \n",
       "4       Los Angeles   Los Angeles, CA 90014  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
